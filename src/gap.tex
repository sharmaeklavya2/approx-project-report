\section{Example - Generalized assignment problem}

In the generalized assignment problem (GAP), there is a set $J = [n]$ of jobs, a set
$M = [m]$ of machines and a set $E \subseteq M \times J$ of feasible assignments.
Each $e \in E$ has an associated cost $c_e$ and a processing time $p_e$.
We are also given the availability $T_i$ for each $i \in M$.
We have to assign each job $j$ to a machine $\sigma(j)$ such that
the total load on every machine $i$ (i.e. sum of processing times of jobs assigned to machine $i$)
is at most $T_i$.

We can view $J$, $M$ and $E$ as a bipartite graph.
Let $\delta(v)$ denote the set of neighbors of vertex $v$.
We will assume WLoG that $(i, j) \in E$ implies that $p_{i,j} \le T_i$.
Also, let $q_i = \max_{j \in \delta(i)} p_{i,j}$.

The canonical LP relaxation for the GAP problem as given by \cite{lrs-book} is
\[ \begin{array}{*4{>{\displaystyle}l}}
\min_x & \sum_{e \in E}{c_e}{x_e} & &
\\ \\ \textrm{where} & \sum_{i \in \delta(j)} x_{i,j} = 1 & \quad \forall j \in J
& \quad \textrm{(each job is scheduled)}
\\ \\ & \sum_{j \in \delta(i)} p_{i,j} x_{i,j} \le T_i & \quad \forall i \in M
& \quad \textrm{(load is at most the availability)}
\\ \\ & x_e \ge 0 & \quad \forall e \in E
\end{array} \]
Let $x^*$ be an optimal solution to this LP.

\subsection{Randomized rounding}

Directly using randomized rounding with GAP is cumbersome, since the constraint
\[ \sum_{i \in \delta(j)} x_{i,j} = 1 \quad \forall j \in J \]
need not be satisfied. As a result, some jobs may not be scheduled
and some jobs will be scheduled on multiple machines.

We'll use a variant of randomized rounding which is strictly better than randomized rounding:
instead of rounding each $x_e$ independently, we'll assign each job independently.
For job $j$, we'll assign it to machine $i$ with probability $x_{i,j}$.
So if $X$ is the rounded solution, then $[X_{i,j}: i \in \delta(j)]$
follows the Multinoulli distribution with $\Pr(X_{i,j} = 1) = x_{i,j}^*$.
Since $\sum_{i \in \delta(j)} x_{i,j}^* = 1$, this is possible and each job
will be assigned to a single machine.
\[ \textrm{Expected load on machine } i
= \E\left(\sum_{j \in \delta(i)} p_{i,j}X_{i,j}\right)
= \sum_{j \in \delta(i)} p_{i,j}x_{i,j}^*
\le T_i \]

In the linear term $\sum_{j \in \delta(i)} p_{i,j}X_{i,j}$,
the variables correspond to different jobs, so they are independent.
Therefore, we can use Bernstein's inequality to prove concentration.
\[ \Pr[\textrm{load on machine } i \ge 2T_i]
\le e^{-\frac{3}{8}} \le 0.6873 \]
This is poor concentration.

\subsection{Sub-isotropic rounding}

We proceed using Strategy-2 as discussed in (\ref{sec:it-str-2}).
We exhibit a subset of constraints $W^{(k)}$ at each iteration $k$ of our rounding such that
$\dim(W^{(k)}) < (1-\delta)n_k$, where $n_k$ is the number of fractional variables
and the constraints not in $W^{(k)}$ will be shown to be satisfied
within an additive error of $\frac{T_i}{1-2\delta}$ where $\delta \in [0,1/2)$
is an input parameter called the slack.
Notice that setting $\delta = 0$ gives us the conventional $2T_i$ approximation result.

Denote fractionally assigned jobs by $R_k$ and let $r_k = \abs{R_k}$.
For machine $i$, define the excess $e_i$ as
\[ e_i = \sum_{j \in \delta(i) \cap R_k} (1 - x_{i,j}^{(k)}) \]
Machine $i$ will get the maximum load that it can possibly get if
all fractional variables get rounded to 1. So, the maximum increase in $i$'s load is
\[ \sum_{j \in \delta(i) \cap R_k} p_{i,j} (1-x_{i,j}^{(k)}) \leq T_i e_i \]
Denote machines with high excess ($e_i > T_i/(1-2\delta)$) by $M_k$ and let $m_k = \abs{M_k}$.
Constraints corresponding to $M_k \cup R_k$ form our $W^{(k)}$. We first show that,
\begin{lemma}
$\dim(W^{(k)}) < (1-\delta)n_k$
\end{lemma}
\begin{proof}
If $i \not\in M_k$, max increase in load is at most $T_i e_i \le \frac{T_i}{1-2\delta}$.
\[ \sum_{i \in M_k} e_i > \frac{m_k}{1-2\delta} \]
\begin{align*}
\sum_{i \in M_k} e_i
&= \sum_{i \in M_k} \sum_{j \in \delta(i) \cap R_k} (1 - x_{i,j}^{(k)})
\\ &\leq \sum_{j \in R_k} \sum_{i \in \delta(j)} (1 - x_{i,j}^{(k)})  \tag{change order of summation}
\\ &= \sum_{j \in R_k} \sum_{i \in \delta(j)} 1 - \sum_{j \in R_k} \sum_{i \in \delta(j)} x_{i,j}^{(k)}
\\ &= n_k - r_k \tag{$\sum_{i \in \delta(j)} x_{i,j}^{(k)} = 1$ by LP constraint}
\end{align*}
Therefore, $m_k < (1-2\delta)(n_k - r_k)$.

Since each job $j \in R_k$ is fractionally assigned to at least 2 machines, $n_k \geq 2r_k$.
\[ \dim(W^{(k)}) \le m_k + r_k < (1-2\delta)n_k + \delta(2r_k) \le (1-\delta)n_k \]
\end{proof}

%Note that the excess of a machine may increase over time, but if it was ever lower than
%$1/(1-2\delta)$, then its load is guaranteed to be less than $T_i\left(1 + 1/(1-2\delta)\right)$.

\begin{theorem}
For any $\delta \in [0,1/2)$, and a starting fractional solution $x^*$,
using sub-isotropic rounding we get an integral solution $X$ such that
\begin{itemize}
    \item maximum increase in load on a machine is $\leq \frac{T_i}{1-2\delta}$.
    \item $\E[X] = x^*$.
    \item $X$ is $O(1/\delta)$-concentrated around $x^*$.
\end{itemize}
\end{theorem}
\begin{proof}
We drop the constraints not in $W^{(k)}$ and those constraints are
additively violated by at most $T_i/(1-2\delta)$
(this corresponds to the `relaxation' trick of iterative rounding).
We proved that $\dim(W^{(k)}) < (1-\delta)n_k$. Therefore, we can invoke sub-isotropic rounding.
%In each iteration $k$, sub-isotropic rounding will give us a $y^{(k)}$ in the nullspace of $W^{(k)}$.

From Theorem \ref{thm:sub-isotropic}, we get that $\E[X] = x^*$ and $X$ is $O(1/\delta)$-concentrated around $x^*$.
$\E[X] = x^*$ also tells us that the expected objective is at most the optimal objective value.
\end{proof}
